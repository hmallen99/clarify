{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GettingStartedResnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5FQFhbadgtX",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started With Trax: Resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQD2AhMDdo3G",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Author: Henry Allen\n",
        "\n",
        "In this tutorial, we will use a Resnet50 to classify handwritten digits from the MNIST dataset, which should be automatically loaded into Colab.\n",
        "\n",
        "Objectives:\n",
        "1. Create an iterator to stream training data\n",
        "2. Classify handrwitten digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wfrZSQMeOAv",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install and import the necessary packages. Notice that there are two separate versions of numpy. We only use the default numpy (onp) in this tutorial, but the jax.numpy package is essential for creating trax layers and custom loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPZ69N32dfwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "7a907501-16e2-4e3c-9ee7-e75a85600edd"
      },
      "source": [
        "! pip install -q -U trax\n",
        "! pip install -q tensorflow\n",
        "\n",
        "import os\n",
        "import numpy as onp\n",
        "import jax.numpy as np\n",
        "\n",
        "import trax\n",
        "import trax.layers as tl\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▉                               | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 61kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 71kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 317kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 327kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 337kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 348kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 358kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 368kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 7.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK_eh89xen32",
        "colab_type": "text"
      },
      "source": [
        "## Data Formatting\n",
        "\n",
        "Import mnist data from colab. These files should already be present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aQyAeOSejHF",
        "colab_type": "code",
        "outputId": "18b7f3e0-2f60-48e2-89ef-f5ad86c092d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data = onp.genfromtxt(\"sample_data/mnist_train_small.csv\", delimiter=',')\n",
        "\n",
        "label = data[:, 0]\n",
        "print(label.shape)\n",
        "\n",
        "train = data[:, 1:]\n",
        "print(train.shape)\n",
        "\n",
        "test = onp.genfromtxt(\"sample_data/mnist_test.csv\", delimiter=',')\n",
        "print(test.shape)\n",
        "\n",
        "test_label = test[:, 0]\n",
        "test_data = test[:, 1:]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000,)\n",
            "(20000, 784)\n",
            "(10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb9a2baHeuFZ",
        "colab_type": "text"
      },
      "source": [
        "## Training Data Iterator and Model\n",
        "\n",
        "Define the model (resnet50_model) and the iterator to stream training data (mnist_iterator2). The iterator yields (x, y) tuples where X is the the training sample and y is the training label. We resize the images to be 256 x 256 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zacSK-ueewpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet50_model(mode):\n",
        "  return trax.models.Resnet50(d_hidden=64, n_output_classes=10, mode=mode)\n",
        "\n",
        "\n",
        "def mnist_iterator2():\n",
        "  \"\"\"\n",
        "  Generator to stream data values from the training set\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  while True:\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(64):\n",
        "      X_i = cv2.resize(train[count].reshape(28, 28), (256, 256)).reshape((256, 256, 1))\n",
        "      X += [X_i]\n",
        "      y += [label[count]]\n",
        "      count += 1\n",
        "      count = count % 20000\n",
        "    X = onp.array(X)\n",
        "    y = onp.array(y)\n",
        "    \n",
        "    yield (X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_INJmqufDa2",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Stream\n",
        "\n",
        "This stream of data is used for inference, it is basically the same as mnist_iterator2, but it streams out the test images and test labels. We use this in the inference step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTF65aIsfH-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mnist_eval_stream():\n",
        "  count = 0\n",
        "  while True:\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(64):\n",
        "      X_i = cv2.resize(test_data[count].reshape((28,28)), (256,256)).reshape((256,256,1))\n",
        "      X += [X_i]\n",
        "      y += [test_label[count]]\n",
        "      count = (count + 1) % 10000\n",
        "    X = onp.array(X)\n",
        "    y = onp.array(y)\n",
        "    yield (X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycga7azxfTEo",
        "colab_type": "text"
      },
      "source": [
        "## Setup Trainer Inputs\n",
        "\n",
        "This initializes the resnet inputs with a call to trax.Supervised.Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsbBRc5fUyb",
        "colab_type": "code",
        "outputId": "0d3f32ba-9790-438b-8850-be1f6fbf1aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "resnet_inputs = trax.supervised.Inputs(lambda _: mnist_iterator2())\n",
        "\n",
        "data_stream = resnet_inputs.train_stream(1)\n",
        "inputs, labels = next(data_stream)\n",
        "print(inputs.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 256, 256, 1)\n",
            "(64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8VEkk4Pf8T7",
        "colab_type": "text"
      },
      "source": [
        "## Train Classifier\n",
        "\n",
        "We need to create an instance of the \"Trainer\" class, and initialize it with the model, loss, and inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVUusgOLf_4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = os.path.expanduser('~/train_mnist_dir/')\n",
        "!rm -f ~/train_mnist_dir/model.pkl\n",
        "\n",
        "trainer = trax.supervised.Trainer(\n",
        "    model=resnet50_model,\n",
        "    loss_fn=trax.layers.CrossEntropyLoss,\n",
        "    optimizer=trax.optimizers.Adam,\n",
        "    lr_schedule=trax.lr.MultifactorSchedule,\n",
        "    inputs=resnet_inputs,\n",
        "    output_dir=output_dir,\n",
        "    has_weights=False) # Make sure to set this to FALSE for Resnet\n",
        "\n",
        "# Train\n",
        "n_epochs  = 3\n",
        "train_steps = 100\n",
        "eval_steps = 20\n",
        "for _ in range(n_epochs):\n",
        "  trainer.train_epoch(train_steps, eval_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIKKbM8nlfrV",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Initialize the prediction model from the training model we just created and perform inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGqzjiqqjSVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_model = resnet50_model(mode='predict')\n",
        "predict_model.init_from_file(\"/root/train_mnist_dir/model.pkl\")\n",
        "\n",
        "eval_stream = mnist_eval_stream()\n",
        "accuracy = 0\n",
        "for i in range(100):\n",
        "  X_test = next(eval_stream)\n",
        "  y_pred = predict_model(X_test[0])\n",
        "  for i in range(len(y_pred)):\n",
        "    if np.argmax(y_pred[i]) == X_test[1][i]:\n",
        "      accuracy += 1\n",
        "\n",
        "print(accuracy / (100 * 64))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}